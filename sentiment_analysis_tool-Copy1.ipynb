{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a63085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command-line environment detected. Using local data file.\n",
      "Loading email metadata from: C:\\Users\\venka\\OneDrive\\Desktop\\auto_researcher\\7.Real_estate_assistant\\real_estate_assistant\\lib\\data\\full_mails.jsonl\n",
      "Successfully loaded 11688 records for metadata.\n",
      "Connecting to ChromaDB Vector Store...\n",
      "Successfully connected to ChromaDB collection.\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "\n",
    "# Import the full email DataFrame\n",
    "from lib.load_data import df\n",
    "\n",
    "# Import helper functions\n",
    "from lib.utils import normalize_list, match_value_in_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade093b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(score):\n",
    "    \"\"\"Classifies a VADER compound score into a category.\"\"\"\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd86ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sentiment_analysis_tool(\n",
    "    sender: str = None,\n",
    "    recipient: str = None,\n",
    "    start_date: str = None,\n",
    "    end_date: str = None,\n",
    "    timeline_granularity: str = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of emails based on filters like sender, recipient, or date range.\n",
    "    It can provide an overall summary or a timeline of sentiment.\n",
    "    Use this for high-level questions like \"what is the overall sentiment in customer emails?\" or \"show me the sentiment timeline for emails from Raja.\"\n",
    "    \"\"\"\n",
    "    print(f\"sentiment_analysis_tool called with: sender={sender}, start_date={start_date}, end_date={end_date}, timeline={timeline_granularity}\")\n",
    "    \n",
    "    if df.is_empty():\n",
    "        return \"Error: Email data is not loaded.\"\n",
    "\n",
    "    temp_df = df.clone()\n",
    "\n",
    "    # --- 1. Apply Filters Sequentially ---\n",
    "    if sender:\n",
    "        sender_lower = sender.lower()\n",
    "        temp_df = temp_df.with_columns(\n",
    "            pl.col(\"from\").map_elements(normalize_list, return_dtype=str).alias(\"from_normalized\")\n",
    "        ).filter(\n",
    "            pl.col(\"from_normalized\").map_elements(lambda x: match_value_in_columns(sender_lower, x), return_dtype=bool)\n",
    "        )\n",
    "\n",
    "    if start_date or end_date or timeline_granularity:\n",
    "        temp_df = temp_df.with_columns(\n",
    "            pl.col(\"date\").str.to_datetime(\"%Y-%m-%dT%H:%M:%SZ\", strict=False).alias(\"date_dt\")\n",
    "        )\n",
    "        if start_date:\n",
    "            temp_df = temp_df.filter(pl.col(\"date_dt\") >= datetime.strptime(start_date, \"%Y-%m-%d\"))\n",
    "        if end_date:\n",
    "            temp_df = temp_df.filter(pl.col(\"date_dt\") <= datetime.strptime(end_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    filtered_df = temp_df\n",
    "    print(f\"Filtered DataFrame has {filtered_df.height} rows after applying filters.\")\n",
    "\n",
    "    if filtered_df.is_empty():\n",
    "        return \"No emails found for the specified criteria.\"\n",
    "\n",
    "    # --- 2. Map & Analyze ---\n",
    "    # THE DEFINITIVE FIX: Access the struct field by its position (index 0) to be robust.\n",
    "    safe_text_extraction_expr = (\n",
    "        pl.when(pl.col(\"body\").is_not_null())\n",
    "        .then(pl.col(\"body\").struct.field(0)) # Access by index for robustness\n",
    "        .otherwise(pl.lit(\"\"))\n",
    "    )\n",
    "    print(f\"Using safe text extraction expression: {safe_text_extraction_expr}\")\n",
    "\n",
    "    select_exprs = [\n",
    "        safe_text_extraction_expr.map_elements(\n",
    "            lambda text: analyzer.polarity_scores(str(text or \"\"))['compound'],\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(\"sentiment_score\")\n",
    "    ]\n",
    "    print(f\"Select expressions for sentiment analysis: {select_exprs}\")\n",
    "    if 'date_dt' in filtered_df.columns:\n",
    "        select_exprs.append(pl.col(\"date_dt\").alias(\"date\"))\n",
    "\n",
    "    sentiments = filtered_df.select(select_exprs).drop_nulls(subset=[\"sentiment_score\"])\n",
    "    print(f\"Sentiment analysis results: {sentiments}\")\n",
    "\n",
    "    if sentiments.is_empty():\n",
    "        return \"Found emails, but could not extract text bodies to analyze sentiment.\"\n",
    "\n",
    "    # --- 3. Reduce & Synthesize ---\n",
    "    granularity = None\n",
    "    if timeline_granularity:\n",
    "        if \"month\" in timeline_granularity.lower():\n",
    "            granularity = \"month\"\n",
    "        elif \"year\" in timeline_granularity.lower():\n",
    "            granularity = \"year\"\n",
    "\n",
    "    if granularity in [\"month\", \"year\"]:\n",
    "        if \"date\" not in sentiments.columns:\n",
    "            return \"Cannot create a timeline without date information.\"\n",
    "            \n",
    "        period = \"1mo\" if granularity == \"month\" else \"1y\"\n",
    "        \n",
    "        timeline_summary = sentiments.drop_nulls(subset=[\"date\"]).sort(\"date\").group_by_dynamic(\"date\", every=period).agg(\n",
    "            pl.mean(\"sentiment_score\").alias(\"average_sentiment\"),\n",
    "            pl.count().alias(\"email_count\")\n",
    "        )\n",
    "        \n",
    "        if timeline_summary.is_empty():\n",
    "            return \"Found emails with valid dates, but could not generate a timeline summary.\"\n",
    "\n",
    "        summary_lines = [f\"Sentiment Timeline Analysis (granularity: {granularity}):\"]\n",
    "        for row in timeline_summary.to_dicts():\n",
    "            period_str = row['date'].strftime('%Y-%m' if granularity == 'month' else '%Y')\n",
    "            avg_sentiment = row['average_sentiment']\n",
    "            sentiment_class = classify_sentiment(avg_sentiment)\n",
    "            summary_lines.append(\n",
    "                f\"- Period: {period_str}, Email Count: {row['email_count']}, \"\n",
    "                f\"Average Sentiment: {avg_sentiment:.2f} ({sentiment_class})\"\n",
    "            )\n",
    "        return \"\\n\".join(summary_lines)\n",
    "\n",
    "    else:\n",
    "        overall_summary = sentiments.select(\n",
    "            pl.mean(\"sentiment_score\").alias(\"average_sentiment\"),\n",
    "            pl.col(\"sentiment_score\").map_elements(lambda s: classify_sentiment(s), return_dtype=str).value_counts().alias(\"sentiment_counts\"),\n",
    "            pl.count().alias(\"total_emails\")\n",
    "        ).to_dicts()[0]\n",
    "\n",
    "        avg_score = overall_summary['average_sentiment']\n",
    "        total_emails = overall_summary['total_emails']\n",
    "        counts = {d['sentiment_score']: d['count'] for d in overall_summary['sentiment_counts']}\n",
    "        \n",
    "        summary = (\n",
    "            f\"Overall Sentiment Analysis Summary:\\n\"\n",
    "            f\"- Total Emails Analyzed: {total_emails}\\n\"\n",
    "            f\"- Average Sentiment Score: {avg_score:.2f} ({classify_sentiment(avg_score)})\\n\"\n",
    "            f\"- Positive Emails: {counts.get('Positive', 0)}\\n\"\n",
    "            f\"- Negative Emails: {counts.get('Negative', 0)}\\n\"\n",
    "            f\"- Neutral Emails: {counts.get('Neutral', 0)}\"\n",
    "        )\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990df468",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sentiment_analysis_tool(\n",
    "    sender: str = None,\n",
    "    recipient: str = None,\n",
    "    start_date: str = None,\n",
    "    end_date: str = None,\n",
    "    timeline_granularity: str = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of emails based on filters like sender, recipient, or date range.\n",
    "    It can provide an overall summary or a timeline of sentiment.\n",
    "    Use this for high-level questions like \"what is the overall sentiment in customer emails?\" or \"show me the sentiment timeline for emails from Raja.\"\n",
    "    \"\"\"\n",
    "    print(f\"sentiment_analysis_tool called with: sender={sender}, start_date={start_date}, end_date={end_date}, timeline={timeline_granularity}\")\n",
    "    \n",
    "    if df.is_empty():\n",
    "        return \"Error: Email data is not loaded.\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    temp_df = df.clone()\n",
    "\n",
    "    # --- 1. Apply Filters Sequentially ---\n",
    "    if sender:\n",
    "        sender_lower = sender.lower()\n",
    "        temp_df = temp_df.with_columns(\n",
    "            pl.col(\"from\").map_elements(normalize_list, return_dtype=str).alias(\"from_normalized\")\n",
    "        ).filter(\n",
    "            pl.col(\"from_normalized\").map_elements(lambda x: match_value_in_columns(sender_lower, x), return_dtype=bool)\n",
    "        )\n",
    "\n",
    "    if start_date or end_date or timeline_granularity:\n",
    "        temp_df = temp_df.with_columns(\n",
    "            pl.col(\"date\").str.to_datetime(\"%Y-%m-%dT%H:%M:%SZ\", strict=False).alias(\"date_dt\")\n",
    "        )\n",
    "        if start_date:\n",
    "            temp_df = temp_df.filter(pl.col(\"date_dt\") >= datetime.strptime(start_date, \"%Y-%m-%d\"))\n",
    "        if end_date:\n",
    "            temp_df = temp_df.filter(pl.col(\"date_dt\") <= datetime.strptime(end_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    filtered_df = temp_df\n",
    "    print(f\"Filtered DataFrame has {filtered_df.height} rows after applying filters.\")\n",
    "\n",
    "    if filtered_df.is_empty():\n",
    "        return \"No emails found for the specified criteria.\"\n",
    "\n",
    "    # --- 2. Map & Analyze ---\n",
    "    # THE DEFINITIVE FIX: Use the field's string name 'text' as required by the function.\n",
    "    safe_text_extraction_expr = (\n",
    "        pl.when(pl.col(\"body\").is_not_null())\n",
    "        .then(pl.col(\"body\").struct.field(\"text\")) # Access by the name 'text'\n",
    "        .otherwise(pl.lit(\"\"))\n",
    "    )\n",
    "\n",
    "    select_exprs = [\n",
    "        safe_text_extraction_expr.map_elements(\n",
    "            lambda text: analyzer.polarity_scores(str(text or \"\"))['compound'],\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(\"sentiment_score\")\n",
    "    ]\n",
    "    if 'date_dt' in filtered_df.columns:\n",
    "        select_exprs.append(pl.col(\"date_dt\").alias(\"date\"))\n",
    "\n",
    "    sentiments = filtered_df.select(select_exprs).drop_nulls(subset=[\"sentiment_score\"])\n",
    "\n",
    "    if sentiments.is_empty():\n",
    "        return \"Found emails, but could not extract text bodies to analyze sentiment.\"\n",
    "\n",
    "    # --- 3. Reduce & Synthesize ---\n",
    "    granularity = None\n",
    "    if timeline_granularity:\n",
    "        if \"month\" in timeline_granularity.lower():\n",
    "            granularity = \"month\"\n",
    "        elif \"year\" in timeline_granularity.lower():\n",
    "            granularity = \"year\"\n",
    "\n",
    "    if granularity in [\"month\", \"year\"]:\n",
    "        if \"date\" not in sentiments.columns:\n",
    "            return \"Cannot create a timeline without date information.\"\n",
    "            \n",
    "        period = \"1mo\" if granularity == \"month\" else \"1y\"\n",
    "        \n",
    "        timeline_summary = sentiments.drop_nulls(subset=[\"date\"]).sort(\"date\").group_by_dynamic(\"date\", every=period).agg(\n",
    "            pl.mean(\"sentiment_score\").alias(\"average_sentiment\"),\n",
    "            pl.count().alias(\"email_count\")\n",
    "        )\n",
    "        \n",
    "        if timeline_summary.is_empty():\n",
    "            return \"Found emails with valid dates, but could not generate a timeline summary.\"\n",
    "\n",
    "        summary_lines = [f\"Sentiment Timeline Analysis (granularity: {granularity}):\"]\n",
    "        for row in timeline_summary.to_dicts():\n",
    "            period_str = row['date'].strftime('%Y-%m' if granularity == 'month' else '%Y')\n",
    "            avg_sentiment = row['average_sentiment']\n",
    "            sentiment_class = classify_sentiment(avg_sentiment)\n",
    "            summary_lines.append(\n",
    "                f\"- Period: {period_str}, Email Count: {row['email_count']}, \"\n",
    "                f\"Average Sentiment: {avg_sentiment:.2f} ({sentiment_class})\"\n",
    "            )\n",
    "        return \"\\n\".join(summary_lines)\n",
    "\n",
    "    else:\n",
    "        overall_summary = sentiments.select(\n",
    "            pl.mean(\"sentiment_score\").alias(\"average_sentiment\"),\n",
    "            pl.col(\"sentiment_score\").map_elements(lambda s: classify_sentiment(s), return_dtype=str).value_counts().alias(\"sentiment_counts\"),\n",
    "            pl.count().alias(\"total_emails\")\n",
    "        ).to_dicts()[0]\n",
    "\n",
    "        avg_score = overall_summary['average_sentiment']\n",
    "        total_emails = overall_summary['total_emails']\n",
    "        counts = {d['sentiment_score']: d['count'] for d in overall_summary['sentiment_counts']}\n",
    "        \n",
    "        summary = (\n",
    "            f\"Overall Sentiment Analysis Summary:\\n\"\n",
    "            f\"- Total Emails Analyzed: {total_emails}\\n\"\n",
    "            f\"- Average Sentiment Score: {avg_score:.2f} ({classify_sentiment(avg_score)})\\n\"\n",
    "            f\"- Positive Emails: {counts.get('Positive', 0)}\\n\"\n",
    "            f\"- Negative Emails: {counts.get('Negative', 0)}\\n\"\n",
    "            f\"- Neutral Emails: {counts.get('Neutral', 0)}\"\n",
    "        )\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b326e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_analysis_tool called with: sender=venkat, start_date=2024-04-08, end_date=2025-09-08, timeline=month\n",
      "Filtered DataFrame has 13 rows after applying filters.\n",
      "Sentiment Timeline Analysis (granularity: month):\n",
      "- Period: 2024-07, Email Count: 3, Average Sentiment: 0.31 (Positive)\n",
      "- Period: 2024-08, Email Count: 3, Average Sentiment: 0.03 (Neutral)\n",
      "- Period: 2024-09, Email Count: 2, Average Sentiment: 0.95 (Positive)\n",
      "- Period: 2025-05, Email Count: 1, Average Sentiment: 0.93 (Positive)\n",
      "- Period: 2025-06, Email Count: 2, Average Sentiment: 0.00 (Neutral)\n",
      "- Period: 2025-07, Email Count: 2, Average Sentiment: 0.49 (Positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_46920\\1005310809.py:84: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"email_count\")\n"
     ]
    }
   ],
   "source": [
    "tool_input = {\n",
    "    \"sender\": \"venkat\",\n",
    "    \"start_date\": \"2024-04-08\",\n",
    "    \"end_date\": \"2025-09-08\",\n",
    "    \"timeline_granularity\": \"month\"  # Corrected argument name\n",
    "}\n",
    "\n",
    "# Use the .invoke() method to run the tool\n",
    "print(sentiment_analysis_tool.invoke(tool_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4df5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
